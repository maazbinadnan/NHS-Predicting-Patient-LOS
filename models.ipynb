{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcNb64ZMtECo"
   },
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BWFu87c9s6hP",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f2da050c-34ca-4542-d25d-0601ea3c7e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJqoM-NwsIpw"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LxZCBur6sGxS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhmAk6lKsZMA"
   },
   "source": [
    "# 1. NORMAL – Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vvIvmwatPq6",
    "outputId": "187ac152-0a81-4597-8a3c-0a3ff0b3e4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NORMAL – Linear Regression (continuous days) ===\n",
      "MAE: 0.31091856973032794\n",
      "RMSE: 0.6492766685703916\n",
      "R²: 0.5933638546196413\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0          1           0          0          24\n",
      "1          4           0          3           8\n",
      "2          1           0          1           1\n",
      "3          1           0          1           1\n",
      "4          1           0          0          23\n",
      "5          5           0          3           2\n",
      "6          1           0          1           0\n",
      "7          1           0          1           1\n",
      "8          1           0          0          24\n",
      "9          1           0          1           0\n",
      "\n",
      "=== INTEGER-DAY METRICS (Linear, normal) ===\n",
      "Int MAE: 0.5764972655728958\n",
      "Int MSE: 0.8536748032546352\n",
      "Int RMSE: 0.9239452382336494\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[   0    0    0    0    0    0]\n",
      " [2060 3436  148   18    1    0]\n",
      " [   2  337  376   52    2    1]\n",
      " [   1   83  248  136   11    1]\n",
      " [   0   37  172  132    2    2]\n",
      " [   0   37  112   83    6    1]]\n",
      "Exact-day accuracy: 0.5270108043217286\n",
      "Accuracy within ±1 day: 0.9266373215953048\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv(\"X_normal_train.csv\")\n",
    "X_test=pd.read_csv(\"X_normal_test.csv\")\n",
    "y_train=pd.read_csv(\"y_normal_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_normal_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=LinearRegression()\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== NORMAL – Linear Regression (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (Linear, normal) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv79DwsjuG5E"
   },
   "source": [
    "# 2. NORMAL – Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L7qwteDWuNWr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NORMAL – Random Forest (continuous days) ===\n",
      "MAE: 0.27166185317482894\n",
      "RMSE: 0.6164885238005062\n",
      "R²: 0.6333966925718073\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0          1           0          1           0\n",
      "1          4           0          3          18\n",
      "2          1           0          1           0\n",
      "3          1           0          1           0\n",
      "4          1           0          1           0\n",
      "5          5           0          2           9\n",
      "6          1           0          1           0\n",
      "7          1           0          1           0\n",
      "8          1           0          1           0\n",
      "9          1           0          1           0\n",
      "\n",
      "=== INTEGER-DAY METRICS (RF, normal) ===\n",
      "Int MAE: 0.28398025877017474\n",
      "Int MSE: 0.5339469120981726\n",
      "Int RMSE: 0.7307167112487387\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[5524  119   20    0    0]\n",
      " [ 301  402   67    0    0]\n",
      " [  68  268  135    9    0]\n",
      " [  32  161  133   19    0]\n",
      " [  21  130   76   12    0]]\n",
      "Exact-day accuracy: 0.8109910630919034\n",
      "Accuracy within ±1 day: 0.9322395624916633\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv(\"X_normal_train.csv\")\n",
    "X_test=pd.read_csv(\"X_normal_test.csv\")\n",
    "y_train=pd.read_csv(\"y_normal_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_normal_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=300,max_depth=None,random_state=42,n_jobs=-1)\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== NORMAL – Random Forest (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (RF, normal) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pT2Ns2j_ux5P"
   },
   "source": [
    "# 3. NORMAL – XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0xK2y5Ibu3DZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NORMAL – XGBoost (continuous days) ===\n",
      "MAE: 0.27418288051469875\n",
      "RMSE: 0.6124342639044911\n",
      "R²: 0.6382026793171705\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0          1           0          0          24\n",
      "1          4           0          3           6\n",
      "2          1           0          0          24\n",
      "3          1           0          0          24\n",
      "4          1           0          0          24\n",
      "5          5           0          2          17\n",
      "6          1           0          1           0\n",
      "7          1           0          1           0\n",
      "8          1           0          0          24\n",
      "9          1           0          1           0\n",
      "\n",
      "=== INTEGER-DAY METRICS (XGB, normal) ===\n",
      "Int MAE: 0.6920101373882886\n",
      "Int MSE: 0.9537148192610377\n",
      "Int RMSE: 0.9765832372414743\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[   0    0    0    0    0    0]\n",
      " [3057 2471  121   13    1    0]\n",
      " [   0  297  436   36    1    0]\n",
      " [   0   69  276  135    0    0]\n",
      " [   0   28  188  117   12    0]\n",
      " [   0   22  141   68    8    0]]\n",
      "Exact-day accuracy: 0.4073629451780712\n",
      "Accuracy within ±1 day: 0.929171668667467\n"
     ]
    }
   ],
   "source": [
    "# NORMAL – XGBoost Regressor\n",
    "\n",
    "X_train=pd.read_csv(\"X_normal_train.csv\")\n",
    "X_test=pd.read_csv(\"X_normal_test.csv\")\n",
    "y_train=pd.read_csv(\"y_normal_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_normal_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=XGBRegressor(objective=\"reg:squarederror\",n_estimators=400,learning_rate=0.05,max_depth=6,subsample=0.8,colsample_bytree=0.8,random_state=42,tree_method=\"hist\")\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== NORMAL – XGBoost (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (XGB, normal) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As per the results i think the best for normal is random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCR5bFnRu6Dg"
   },
   "source": [
    "# 4. OUTLIERS – SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "osiHvO2YvFG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTLIER – SVR (continuous days) ===\n",
      "MAE: 6.549665962810095\n",
      "RMSE: 11.90454279979262\n",
      "R²: 0.08325819176836646\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0         11           0          8          16\n",
      "1          6          24         13          11\n",
      "2          8           0         12           4\n",
      "3         12           0         17          14\n",
      "4         10           0         16          18\n",
      "5          6          24          8          17\n",
      "6         19          24         20          19\n",
      "7         17          24         16           5\n",
      "8          9           0          8          23\n",
      "9          6          24         10          16\n",
      "\n",
      "=== INTEGER-DAY METRICS (SVR, outliers) ===\n",
      "Int MAE: 6.514318442153494\n",
      "Int MSE: 142.08132875143184\n",
      "Int RMSE: 11.919787277943842\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  6 31 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Exact-day accuracy: 0.09163802978235967\n",
      "Accuracy within ±1 day: 0.2542955326460481\n"
     ]
    }
   ],
   "source": [
    "# OUTLIERS – SVR\n",
    "\n",
    "X_train=pd.read_csv(\"X_outliers_train.csv\")\n",
    "X_test=pd.read_csv(\"X_outliers_test.csv\")\n",
    "y_train=pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=SVR(kernel=\"rbf\",C=5.0,epsilon=0.1)\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== OUTLIER – SVR (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (SVR, outliers) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEUslw68vHqo"
   },
   "source": [
    "# 5. OUTLIERS – LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZuFpRJayvNL3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTLIER – LightGBM (continuous days) ===\n",
      "MAE: 6.288392035426221\n",
      "RMSE: 11.564608946643167\n",
      "R²: 0.13486576130939998\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0         11           0          8          20\n",
      "1          6          24         21          10\n",
      "2          8           0          9          17\n",
      "3         12           0         16           6\n",
      "4         10           0         14           5\n",
      "5          6          24          7          18\n",
      "6         19          24         22          10\n",
      "7         17          24          9          12\n",
      "8          9           0          6           7\n",
      "9          6          24         11           2\n",
      "\n",
      "=== INTEGER-DAY METRICS (LGBM, outliers) ===\n",
      "Int MAE: 6.270332187857961\n",
      "Int MSE: 134.37571592210767\n",
      "Int RMSE: 11.592053999275006\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1 10 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Exact-day accuracy: 0.09392898052691867\n",
      "Accuracy within ±1 day: 0.27720504009163804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# OUTLIERS – LightGBM Regressor\n",
    "\n",
    "X_train=pd.read_csv(\"X_outliers_train.csv\")\n",
    "X_test=pd.read_csv(\"X_outliers_test.csv\")\n",
    "y_train=pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=LGBMRegressor(n_estimators=400,learning_rate=0.05,num_leaves=31,random_state=42,verbose=-1)\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== OUTLIER – LightGBM (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (LGBM, outliers) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY-DK-q9vWhL"
   },
   "source": [
    "# 6. OUTLIERS – KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "67AvFYNEvb9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTLIER – KNN (continuous days) ===\n",
      "MAE: 6.456946318945638\n",
      "RMSE: 12.180224268627319\n",
      "R²: 0.040307355818123614\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0         11           0          8          23\n",
      "1          6          24         10           4\n",
      "2          8           0         13           5\n",
      "3         12           0         13           9\n",
      "4         10           0         14           9\n",
      "5          6          24         11           9\n",
      "6         19          24         15          24\n",
      "7         17          24          9          17\n",
      "8          9           0         10          16\n",
      "9          6          24          9          17\n",
      "\n",
      "=== INTEGER-DAY METRICS (KNN, outliers) ===\n",
      "Int MAE: 6.419243986254296\n",
      "Int MSE: 148.971363115693\n",
      "Int RMSE: 12.205382546880413\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[35 37 41 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [11 14 12 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Exact-day accuracy: 0.09965635738831616\n",
      "Accuracy within ±1 day: 0.2588774341351661\n"
     ]
    }
   ],
   "source": [
    "# OUTLIERS – KNN Regressor\n",
    "\n",
    "X_train=pd.read_csv(\"X_outliers_train.csv\")\n",
    "X_test=pd.read_csv(\"X_outliers_test.csv\")\n",
    "y_train=pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "y_test=pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features=X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "categorical_features=X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"scaler\",StandardScaler())])\n",
    "categorical_transformer=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\")),(\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "preprocessor=ColumnTransformer(transformers=[(\"num\",numeric_transformer,numeric_features),(\"cat\",categorical_transformer,categorical_features)])\n",
    "\n",
    "model=KNeighborsRegressor(n_neighbors=10,weights=\"distance\")\n",
    "pipe=Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_log=pipe.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== OUTLIER – KNN (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (KNN, outliers) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. OUTLIER – XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTLIER – XGBoost (continuous days) ===\n",
      "MAE: 6.1782480640782795\n",
      "RMSE: 11.526699204889399\n",
      "R²: 0.14052842747674232\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0         11           0         10           1\n",
      "1          6          24         16           5\n",
      "2          8           0          9          19\n",
      "3         12           0         16          23\n",
      "4         10           0         13          17\n",
      "5          6          24          8          15\n",
      "6         19          24         26          22\n",
      "7         17          24          9           8\n",
      "8          9           0          7          13\n",
      "9          6          24         10           7\n",
      "\n",
      "=== INTEGER-DAY METRICS (XGBoost, outliers) ===\n",
      "Int MAE: 6.13631156930126\n",
      "Int MSE: 133.19931271477662\n",
      "Int RMSE: 11.541200661749913\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 3 27 51 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Exact-day accuracy: 0.10652920962199312\n",
      "Accuracy within ±1 day: 0.27376861397479957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train = pd.read_csv(\"X_outliers_train.csv\")\n",
    "X_test = pd.read_csv(\"X_outliers_test.csv\")\n",
    "y_train = pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "y_test = pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=2,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", xgb_model)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred_log = pipe.predict(X_test)\n",
    "\n",
    "y_true_days = np.exp(y_test)\n",
    "y_pred_days = np.exp(y_pred_log)\n",
    "\n",
    "mae = mean_absolute_error(y_true_days, y_pred_days)\n",
    "rmse = mean_squared_error(y_true_days, y_pred_days)**0.5\n",
    "r2 = r2_score(y_true_days, y_pred_days)\n",
    "\n",
    "print(\"\\n=== OUTLIER – XGBoost (continuous days) ===\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "true_days_int = np.floor(y_true_days).astype(int)\n",
    "true_hours = np.round((y_true_days - true_days_int) * 24).astype(int)\n",
    "pred_days_int = np.floor(y_pred_days).astype(int)\n",
    "pred_hours = np.round((y_pred_days - pred_days_int) * 24).astype(int)\n",
    "\n",
    "results_df = X_test.copy()\n",
    "results_df[\"true_days\"] = true_days_int\n",
    "results_df[\"true_hours\"] = true_hours\n",
    "results_df[\"pred_days\"] = pred_days_int\n",
    "results_df[\"pred_hours\"] = pred_hours\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\", \"true_hours\", \"pred_days\", \"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int = true_days_int\n",
    "y_pred_int = pred_days_int\n",
    "\n",
    "int_mae = mean_absolute_error(y_true_int, y_pred_int)\n",
    "int_mse = mean_squared_error(y_true_int, y_pred_int)\n",
    "int_rmse = int_mse**0.5\n",
    "cm = confusion_matrix(y_true_int, y_pred_int)\n",
    "acc_exact = accuracy_score(y_true_int, y_pred_int)\n",
    "acc_pm1 = np.mean(np.abs(y_true_int - y_pred_int) <= 1)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (XGBoost, outliers) ===\")\n",
    "print(\"Int MAE:\", int_mae)\n",
    "print(\"Int MSE:\", int_mse)\n",
    "print(\"Int RMSE:\", int_rmse)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\", acc_exact)\n",
    "print(\"Accuracy within ±1 day:\", acc_pm1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. OUTLIERS – CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5709300\ttest: 0.5878208\tbest: 0.5878208 (0)\ttotal: 85.5ms\tremaining: 42.6s\n",
      "100:\tlearn: 0.4355773\ttest: 0.5232511\tbest: 0.5232511 (100)\ttotal: 9.75s\tremaining: 38.5s\n",
      "200:\tlearn: 0.3945914\ttest: 0.5221826\tbest: 0.5219892 (168)\ttotal: 19.7s\tremaining: 29.3s\n",
      "300:\tlearn: 0.3557565\ttest: 0.5230698\tbest: 0.5212169 (245)\ttotal: 30.8s\tremaining: 20.3s\n",
      "400:\tlearn: 0.3262781\ttest: 0.5234936\tbest: 0.5212169 (245)\ttotal: 41.3s\tremaining: 10.2s\n",
      "499:\tlearn: 0.3024313\ttest: 0.5237225\tbest: 0.5212169 (245)\ttotal: 51.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5212169001\n",
      "bestIteration = 245\n",
      "\n",
      "Shrink model to first 246 iterations.\n",
      "\n",
      "=== OUTLIER – CatBoost_Outliers (continuous days) ===\n",
      "MAE: 6.15712086644807\n",
      "RMSE: 11.603231805753916\n",
      "R²: 0.12907745406320736\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0         11           0         10           8\n",
      "1          6          24         14           1\n",
      "2          8           0          9          11\n",
      "3         12           0         17          16\n",
      "4         10           0         13          22\n",
      "5          6          24          8          21\n",
      "6         19          24         19           8\n",
      "7         17          24         10           8\n",
      "8          9           0          7          14\n",
      "9          6          24          9           6\n",
      "\n",
      "=== INTEGER-DAY METRICS (CatBoost_Outliers) ===\n",
      "Int MAE: 6.115693012600229\n",
      "Int MSE: 135.53379152348225\n",
      "Int RMSE: 11.64189810655815\n",
      "\n",
      "Confusion matrix:\n",
      "[[34 42 36 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 7 19 16 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Exact-day accuracy: 0.10996563573883161\n",
      "Accuracy within ±1 day: 0.2806414662084765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, accuracy_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "X_train = pd.read_csv(\"X_outliers_train.csv\")\n",
    "X_test = pd.read_csv(\"X_outliers_test.csv\")\n",
    "y_train = pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "y_test = pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "categorical_indices = np.where(X_train.dtypes == \"object\")[0]\n",
    "\n",
    "cb_model = CatBoostRegressor(\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"RMSE\",\n",
    "    n_estimators=500,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cb_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=categorical_indices,\n",
    "    eval_set=(X_test, y_test),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "y_pred_log = cb_model.predict(X_test)\n",
    "\n",
    "y_true_days = np.exp(y_test)\n",
    "y_pred_days = np.exp(y_pred_log)\n",
    "\n",
    "mae = mean_absolute_error(y_true_days, y_pred_days)\n",
    "rmse = mean_squared_error(y_true_days, y_pred_days)**0.5\n",
    "r2 = r2_score(y_true_days, y_pred_days)\n",
    "\n",
    "print(\"\\n=== OUTLIER – CatBoost_Outliers (continuous days) ===\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "true_days_int = np.floor(y_true_days).astype(int)\n",
    "true_hours = np.round((y_true_days - true_days_int) * 24).astype(int)\n",
    "pred_days_int = np.floor(y_pred_days).astype(int)\n",
    "pred_hours = np.round((y_pred_days - pred_days_int) * 24).astype(int)\n",
    "\n",
    "results_df = X_test.copy()\n",
    "results_df[\"true_days\"] = true_days_int\n",
    "results_df[\"true_hours\"] = true_hours\n",
    "results_df[\"pred_days\"] = pred_days_int\n",
    "results_df[\"pred_hours\"] = pred_hours\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\", \"true_hours\", \"pred_days\", \"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int = true_days_int\n",
    "y_pred_int = pred_days_int\n",
    "\n",
    "int_mae = mean_absolute_error(y_true_int, y_pred_int)\n",
    "int_mse = mean_squared_error(y_true_int, y_pred_int)\n",
    "int_rmse = int_mse**0.5\n",
    "\n",
    "cm = confusion_matrix(y_true_int, y_pred_int)\n",
    "acc_exact = accuracy_score(y_true_int, y_pred_int)\n",
    "acc_pm1 = np.mean(np.abs(y_true_int - y_pred_int) <= 1)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (CatBoost_Outliers) ===\")\n",
    "print(\"Int MAE:\", int_mae)\n",
    "print(\"Int MSE:\", int_mse)\n",
    "print(\"Int RMSE:\", int_rmse)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\", acc_exact)\n",
    "print(\"Accuracy within ±1 day:\", acc_pm1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As of for outliers we can keep our first option as xgboost as it preformed well in every thing and also we may consider catboost for its accuracy but the rmse value is low compared to xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxdq6yZovikx"
   },
   "source": [
    "# 8. COMBINED – CatBoost Regressor (Normal + Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vzBjRLY3vlQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7855462\ttest: 0.7953593\tbest: 0.7953593 (0)\ttotal: 310ms\tremaining: 2m 34s\n",
      "100:\tlearn: 0.2856519\ttest: 0.3045991\tbest: 0.3045991 (100)\ttotal: 13s\tremaining: 51.4s\n",
      "200:\tlearn: 0.2725077\ttest: 0.2986104\tbest: 0.2986104 (200)\ttotal: 25.8s\tremaining: 38.4s\n",
      "300:\tlearn: 0.2644401\ttest: 0.2963805\tbest: 0.2963805 (300)\ttotal: 37.9s\tremaining: 25.1s\n",
      "400:\tlearn: 0.2568369\ttest: 0.2946680\tbest: 0.2946680 (400)\ttotal: 50s\tremaining: 12.4s\n",
      "499:\tlearn: 0.2506862\ttest: 0.2939606\tbest: 0.2939369 (496)\ttotal: 1m 4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2939368593\n",
      "bestIteration = 496\n",
      "\n",
      "Shrink model to first 497 iterations.\n",
      "\n",
      "=== COMBINED – CatBoost (continuous days) ===\n",
      "MAE: 0.8937557801908974\n",
      "RMSE: 3.834997107756231\n",
      "R²: 0.5397387457851166\n",
      "\n",
      "Sample predictions (first 10):\n",
      "   true_days  true_hours  pred_days  pred_hours\n",
      "0          1           0          1           0\n",
      "1          4           0          3           6\n",
      "2          1           0          1           0\n",
      "3          1           0          0          24\n",
      "4          1           0          0          24\n",
      "5          5           0          2          13\n",
      "6          1           0          0          24\n",
      "7          1           0          1           0\n",
      "8          1           0          1           0\n",
      "9          1           0          1           0\n",
      "\n",
      "=== INTEGER-DAY METRICS (CatBoost, combined) ===\n",
      "Int MAE: 1.1408602150537634\n",
      "Int MSE: 15.221863799283154\n",
      "Int RMSE: 3.9015207034287482\n",
      "\n",
      "Confusion matrix (integer days):\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [2006 3527  122 ...    0    0    0]\n",
      " [   5  295  426 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "Exact-day accuracy: 0.4986857825567503\n",
      "Accuracy within ±1 day: 0.860931899641577\n"
     ]
    }
   ],
   "source": [
    "# COMBINED – CatBoost Regressor (normal + outliers merged)\n",
    "\n",
    "Xn_train=pd.read_csv(\"X_normal_train.csv\")\n",
    "Xn_test=pd.read_csv(\"X_normal_test.csv\")\n",
    "yn_train=pd.read_csv(\"y_normal_train.csv\")[\"spell_episode_los\"]\n",
    "yn_test=pd.read_csv(\"y_normal_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "Xo_train=pd.read_csv(\"X_outliers_train.csv\")\n",
    "Xo_test=pd.read_csv(\"X_outliers_test.csv\")\n",
    "yo_train=pd.read_csv(\"y_outliers_train.csv\")[\"spell_episode_los\"]\n",
    "yo_test=pd.read_csv(\"y_outliers_test.csv\")[\"spell_episode_los\"]\n",
    "\n",
    "X_train=pd.concat([Xn_train,Xo_train],axis=0).reset_index(drop=True)\n",
    "X_test=pd.concat([Xn_test,Xo_test],axis=0).reset_index(drop=True)\n",
    "y_train=pd.concat([yn_train,yo_train],axis=0).reset_index(drop=True)\n",
    "y_test=pd.concat([yn_test,yo_test],axis=0).reset_index(drop=True)\n",
    "\n",
    "categorical_features=np.where(X_train.dtypes==\"object\")[0]\n",
    "\n",
    "model=CatBoostRegressor(depth=8,learning_rate=0.05,loss_function=\"RMSE\",n_estimators=500,random_seed=42,verbose=100)\n",
    "model.fit(X_train,y_train,cat_features=categorical_features,eval_set=(X_test,y_test),use_best_model=True)\n",
    "\n",
    "y_pred_log=model.predict(X_test)\n",
    "\n",
    "y_true_days=np.exp(y_test)\n",
    "y_pred_days=np.exp(y_pred_log)\n",
    "\n",
    "mae=mean_absolute_error(y_true_days,y_pred_days)\n",
    "rmse=mean_squared_error(y_true_days,y_pred_days)**0.5\n",
    "r2=r2_score(y_true_days,y_pred_days)\n",
    "\n",
    "print(\"\\n=== COMBINED – CatBoost (continuous days) ===\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R²:\",r2)\n",
    "\n",
    "true_days_int=np.floor(y_true_days).astype(int)\n",
    "true_hours=np.round((y_true_days-true_days_int)*24).astype(int)\n",
    "pred_days_int=np.floor(y_pred_days).astype(int)\n",
    "pred_hours=np.round((y_pred_days-pred_days_int)*24).astype(int)\n",
    "\n",
    "results_df=X_test.copy()\n",
    "results_df[\"true_days\"]=true_days_int\n",
    "results_df[\"true_hours\"]=true_hours\n",
    "results_df[\"pred_days\"]=pred_days_int\n",
    "results_df[\"pred_hours\"]=pred_hours\n",
    "results_df[\"pred_days_decimal\"]=y_pred_days\n",
    "\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(results_df[[\"true_days\",\"true_hours\",\"pred_days\",\"pred_hours\"]].head(10))\n",
    "\n",
    "y_true_int=true_days_int\n",
    "y_pred_int=pred_days_int\n",
    "\n",
    "int_mse=mean_squared_error(y_true_int,y_pred_int)\n",
    "int_rmse=int_mse**0.5\n",
    "int_mae=mean_absolute_error(y_true_int,y_pred_int)\n",
    "\n",
    "print(\"\\n=== INTEGER-DAY METRICS (CatBoost, combined) ===\")\n",
    "print(\"Int MAE:\",int_mae)\n",
    "print(\"Int MSE:\",int_mse)\n",
    "print(\"Int RMSE:\",int_rmse)\n",
    "\n",
    "cm=confusion_matrix(y_true_int,y_pred_int)\n",
    "acc=accuracy_score(y_true_int,y_pred_int)\n",
    "within_1_day=np.mean(np.abs(y_true_int-y_pred_int)<=1)\n",
    "\n",
    "print(\"\\nConfusion matrix (integer days):\")\n",
    "print(cm)\n",
    "print(\"Exact-day accuracy:\",acc)\n",
    "print(\"Accuracy within ±1 day:\",within_1_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the final combined model which i have used catboost."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
